{
  "gemma": {
    "max_new_tokens": 16,
    "do_sample": true,
    "temperature": 0.01,
    "top_p": 0.05,
    "repetition_penalty": 1.5
  },
  "mistral": {
    "max_new_tokens": 16,
    "do_sample": true,
    "temperature": 1.9,
    "top_p": 0.1
  },
  "llama": {
    "max_new_tokens": 16,
    "do_sample": true,
    "temperature": 1.9,
    "top_p": 0.1
  }
}