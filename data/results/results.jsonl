{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:30", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.8303571428571429, "f1": 0.5321364661832094, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:34", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:39", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.8214285714285714, "f1": 0.5233161198628632, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:44", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:49", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.8035714285714286, "f1": 0.5400843423033544, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:54", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:56:59", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.8125, "f1": 0.5240811301210455, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 17:57:04", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:08", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.5934065934065934, "f1": 0.40494482713293295, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:13", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:18", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.5769230769230769, "f1": 0.3974151844707757, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:23", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:28", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.45604395604395603, "f1": 0.32635057554799074, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:33", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:38", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.46703296703296704, "f1": 0.3297381970539692, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 17:57:43", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:57:47", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.39285714285714285, "f1": 0.2792596933878446, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:57:52", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:57:57", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.3125, "f1": 0.23799430281559322, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:58:02", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:58:07", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.044642857142857144, "f1": 0.10932652052662557, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:58:12", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:58:17", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.044642857142857144, "f1": 0.10496185254531529, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 17:58:21", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:26", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.3125, "f1": 0.2778625535560695, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:31", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:36", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.2556818181818182, "f1": 0.23838654197110073, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:41", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:46", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.045454545454545456, "f1": 0.08362841388409571, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:51", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:58:56", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.03977272727272727, "f1": 0.09949673117286756, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 17:59:00", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.6428571428571429, "f1": 0.4361636000554067, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:00:53", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.6964285714285714, "f1": 0.5190183328576184, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:00:57", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.6517857142857143, "f1": 0.44652133580704995, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:01:03", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.6875, "f1": 0.5136466707895277, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:01:07", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.6339285714285714, "f1": 0.3905171334267972, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:01:12", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.7053571428571429, "f1": 0.5538891663891661, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:01:17", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.5357142857142857, "f1": 0.3516718415221565, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:01:22", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.6875, "f1": 0.4847696698143125, "model": "mistral", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-26 18:01:27", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.532967032967033, "f1": 0.3742918053285314, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:01:32", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.5164835164835165, "f1": 0.41171903493332074, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:01:37", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.4065934065934066, "f1": 0.3035399582102877, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:01:42", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.46153846153846156, "f1": 0.3878609028334303, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:01:46", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.3901098901098901, "f1": 0.2505251392290822, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:01:51", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.3791208791208791, "f1": 0.3132777398210494, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:01:56", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.32967032967032966, "f1": 0.22745633577081537, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:02:01", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.4010989010989011, "f1": 0.3038428756835349, "model": "mistral", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-26 18:02:06", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.44642857142857145, "f1": 0.338206892221985, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:11", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.45535714285714285, "f1": 0.38721182559638984, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:16", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.25, "f1": 0.21796227086405665, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:21", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.35714285714285715, "f1": 0.3138334704511174, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:26", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.09821428571428571, "f1": 0.08871512911691481, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:31", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.07142857142857142, "f1": 0.10114488685917256, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:35", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.10714285714285714, "f1": 0.06832658908551766, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:40", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.08035714285714286, "f1": 0.10147387334887335, "model": "mistral", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-26 18:02:45", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.3806818181818182, "f1": 0.3244947187979481, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:02:50", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.3181818181818182, "f1": 0.30763678689067436, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:02:55", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.22727272727272727, "f1": 0.20515171347478553, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:03:00", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.23863636363636365, "f1": 0.2466499499011636, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:03:05", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.13068181818181818, "f1": 0.0782606996273264, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:03:10", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.0625, "f1": 0.10112947806798073, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:03:15", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.11363636363636363, "f1": 0.09854539399993945, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:03:20", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.06818181818181818, "f1": 0.10793569732406633, "model": "mistral", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-26 18:03:25", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 1.9, "top_p": 0.1}}

{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:04", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.48249027237354086, "f1": 0.21493565984454277, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:09", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:14", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.2162312395775431, "f1": 0.10054881474281416, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:19", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:24", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.0867148415786548, "f1": 0.11392859015486115, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:29", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:35", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.1096905688345377, "f1": 0.07179561312592506, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 18:20:40", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:52:53", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.48249027237354086, "f1": 0.21493565984454277, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:52:59", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:53:04", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.2162312395775431, "f1": 0.10054881474281416, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:53:09", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:53:14", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.0867148415786548, "f1": 0.11392859015486115, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:53:19", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0, "f1": 0, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:53:24", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.1096905688345377, "f1": 0.07179561312592506, "model": "llama", "dataset": "TR_l2", "subset": "test.jsonl", "timestamp": "2024-11-26 19:53:29", "gen_params": {"max_new_tokens": 128, "do_sample": true, "temperature": 0.1, "top_p": 0.1, "repetition_penalty": 1.6, "penalty_alpha": 0.1}}
