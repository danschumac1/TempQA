{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.6785714285714286, "f1": 0.3315497469384024, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:15:32", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.6607142857142857, "f1": 0.35697952986555925, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:15:36", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.6160714285714286, "f1": 0.28988156742883636, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:15:41", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.6875, "f1": 0.3671529552963376, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:15:46", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.6428571428571429, "f1": 0.29938307345082554, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:15:51", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.6696428571428571, "f1": 0.36287872912016, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:15:56", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.5625, "f1": 0.28834314703675606, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:16:01", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.5714285714285714, "f1": 0.3224844748658881, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-05 12:16:06", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.554945054945055, "f1": 0.25225218830584045, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:11", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.5274725274725275, "f1": 0.27761967413542615, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:16", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.5054945054945055, "f1": 0.2337921989667303, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:21", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.521978021978022, "f1": 0.2755140562590465, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:26", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.46153846153846156, "f1": 0.18804222244752306, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:31", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.4945054945054945, "f1": 0.222947640736315, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:36", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.4230769230769231, "f1": 0.19253903167734326, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:40", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.4340659340659341, "f1": 0.21712319068790006, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-05 12:16:45", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.3392857142857143, "f1": 0.17778944049495743, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:16:50", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.32142857142857145, "f1": 0.19679813877858945, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:16:55", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.29464285714285715, "f1": 0.14693621038158852, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:17:00", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.2857142857142857, "f1": 0.17977677020785113, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:17:05", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.16071428571428573, "f1": 0.07879669324576952, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:17:10", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.16071428571428573, "f1": 0.0666718671887845, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:17:15", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.16071428571428573, "f1": 0.07094964524364634, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:17:20", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.16071428571428573, "f1": 0.09671309057393149, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-05 12:17:25", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "relevant_context", "accuracy": 0.4034090909090909, "f1": 0.18784394174601401, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:30", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "relevant_context", "accuracy": 0.32954545454545453, "f1": 0.1931969765758993, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:35", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "wrong_date_context", "accuracy": 0.32386363636363635, "f1": 0.15165322645269166, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:40", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "wrong_date_context", "accuracy": 0.32954545454545453, "f1": 0.15905134465286094, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:45", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "random_context", "accuracy": 0.29545454545454547, "f1": 0.09569943735041885, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:50", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "random_context", "accuracy": 0.2556818181818182, "f1": 0.08306010334225923, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:54", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context", "eval_on": "no_context", "accuracy": 0.26704545454545453, "f1": 0.0838703067338123, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:17:59", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context", "eval_on": "no_context", "accuracy": 0.25, "f1": 0.08578212952377386, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-05 12:18:04", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "relevant_context", "accuracy": 0.8660714285714286, "f1": 0.43340460018506227, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-06 12:04:17", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "wrong_date_context", "accuracy": 0.8571428571428571, "f1": 0.42808091622429834, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-06 12:04:22", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "random_context", "accuracy": 0.8660714285714286, "f1": 0.44460822207670914, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-06 12:04:27", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "no_context", "accuracy": 0.875, "f1": 0.42996959564711645, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-06 12:04:32", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "relevant_context", "accuracy": 0.6208791208791209, "f1": 0.32105022274663014, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-06 12:04:37", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "wrong_date_context", "accuracy": 0.6208791208791209, "f1": 0.31723783178041, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-06 12:04:41", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "random_context", "accuracy": 0.5824175824175825, "f1": 0.2968386736082274, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-06 12:04:46", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "no_context", "accuracy": 0.5879120879120879, "f1": 0.28258067437123674, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-06 12:04:51", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "relevant_context", "accuracy": 0.30357142857142855, "f1": 0.17779419889658718, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-06 12:04:56", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "wrong_date_context", "accuracy": 0.2857142857142857, "f1": 0.1546924319660388, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-06 12:05:01", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "random_context", "accuracy": 0.13392857142857142, "f1": 0.09917721451542216, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-06 12:05:06", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "no_context", "accuracy": 0.16071428571428573, "f1": 0.09435372633902044, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-06 12:05:11", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "relevant_context", "accuracy": 0.3181818181818182, "f1": 0.17382401905955935, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-06 12:05:16", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "wrong_date_context", "accuracy": 0.30113636363636365, "f1": 0.15792550042875472, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-06 12:05:21", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "random_context", "accuracy": 0.19318181818181818, "f1": 0.09361596514002928, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-06 12:05:26", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "mixed_context-stacked", "eval_on": "no_context", "accuracy": 0.22727272727272727, "f1": 0.10437208457763263, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-06 12:05:31", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "relevant_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-07 19:59:28", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "wrong_date_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-07 19:59:33", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "random_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-07 19:59:38", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "no_context", "accuracy": 0.7857142857142857, "f1": 0.4246483948136976, "model": "llama", "dataset": "MenatQA", "subset": "counterfactual", "timestamp": "2024-11-07 19:59:42", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "relevant_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-07 19:59:47", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "wrong_date_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-07 19:59:52", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "random_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-07 19:59:57", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "no_context", "accuracy": 0.5164835164835165, "f1": 0.2727475835988066, "model": "llama", "dataset": "MenatQA", "subset": "order", "timestamp": "2024-11-07 20:00:02", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "relevant_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-07 20:00:07", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "wrong_date_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-07 20:00:12", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "random_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-07 20:00:17", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "no_context", "accuracy": 0.19642857142857142, "f1": 0.1141892785669046, "model": "llama", "dataset": "MenatQA", "subset": "scope", "timestamp": "2024-11-07 20:00:22", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "relevant_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-07 20:00:27", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "wrong_date_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-07 20:00:32", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "random_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-07 20:00:37", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}
{"trained_on": "relevant_context-24epochs", "eval_on": "no_context", "accuracy": 0.17045454545454544, "f1": 0.09888016019498223, "model": "llama", "dataset": "MenatQA", "subset": "scope_expand", "timestamp": "2024-11-07 20:00:42", "gen_params": {"max_new_tokens": 16, "do_sample": true, "temperature": 0.1, "top_p": 0.1}}